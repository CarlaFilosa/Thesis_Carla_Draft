\chapter{Conclusion and discussion}
\label{chap:Conclusion}
Neuronal models of reinforcement learning assume interactions of midbrain dopamine neurons in ventral tegmental area (VTA) and ventral striatum (VS) to compute the differences between anticipated and received outcomes. These signals define the reward prediction error (RPE), essential in learning to predict the future and maximise the reward. However how RPE signals are formed and encoded in VS-VTA circuit remains elusive.\\We studied the formation of (RPE) signals in VS-VTA interregional assemblies during learning to broaden our knowledge of the underpinnings of such signals. From this study we have drawn the following conclusion:
\begin{itemize}
    \item \textbf{Assembly-pairs occurrence, time scales and directionality:}\\We recorded neuronal activity in VS, including pallidum (VP), and VTA during a reversal learning go-no task in mice. In VS/VP striatal projection neurons (SPN) and fast spiking neurons (FSN) were the more frequent cells types. In VTA we recorded a good fraction of dopamine neurons (DAN)and  gabaergic (GABA) neurons. In this data set we further applied an unsupervised cell-assemblies detection method, to detect assemblies of synchronously ($lag=0$) and sequentially ($lag\neq0$) active units at arbitrary time scales ($\Delta$).\\Using $\chi^2$ test, we assessed whether different cell-types had different tendency to agglomerate together; that revealed that two groups of units had high tendency to agglomerate in assembly, namely SPN and DAN together, and FSN and GABA together.\\While we observed assemblies of temporal precision at the scale of few tens of milliseconds only within either VS or VTA, assemblies of lower temporal precision were detected across VS-VTA units. The temporal precision of this last group displayed a bimodal distribution with peaks around hundred milliseconds and one second.\\We focused on the more precise temporal scale first not to interfere with the characteristic temporal scales of the experiment, such as the odor duration; second because the reward prediction error signals typically involve fast temporal scales (few hundred milliseconds). Interestingly the lags of more temporally precise assemblies displayed an asymmetric distribution indicating VS leading VTA.\\ Specifically, these directional assemblies were composed of SPN and DAN neurons. The directionality was functional: the units in assemblies did not have to be directly connected by a synapse. Indeed, the SPN-DAN communication could occur both directly and relayed through interspersed neurons.\\In summary, we revealed here the multiple time scale and functional network of the striatum mid-brain interaction during a reversal assignment task.  
    \item \textbf{Assembly-pairs activity patterns:}\\
    Assemblies with different time scales and directionalities segregated different task related activity patterns.\\A large fraction of SPN-DAN assembly-pairs became selectively active at the rewarded stimulus onset and remained active for few hundred millisecond ([100, 400] ms); whereas a small fraction were active at the time of the reward retrieval. This kind of activation resembled the stereotypical RPE signals. Indeed RPE signal is formed after few hundred milliseconds from the stimulus onset. Usually preceded by the phasic activation of the stimulus detection, the RPE signal evolves then in a broader activation, to value the stimulus and predict the reward (\cite{Tobler2003}, \cite{Nomoto2010}, \cite{Schultz2016}).\\%Thus, we assumed SPN-DAN assembly-pairs conveying the valuation component of RPE signals.\\
    FSN-DAN pairs, conversely, were unselectively and phasic activated by rewarded or unrewarded stimuli. Furthermore their activation was diverse among different assembly-pairs, thereby suggesting that those assembly-pair types could be involved in motivational or hedonic signals, rather than in RPE signals.\\These results suggested that different assembly-pair types with DAN had different reward-related coding features. We putted forth the concept that SPN-DAN specifically conveyed the valuation of component RPE. This component constitutes biological implementations of the crucial error term for reinforcement learning according to the Rescorlaâ€“Wagner-like models. 
    \item \textbf{Correlation with reinforcement learning model function:}\\The activity patterns gave us information about the average activity across trials in different moments of the trial, by considering how the signal evolved within the trial; however this view lacked the trial by trial evolution. Nevertheless, the assembly-pair activity got modified by the learning process, as the animal, in base of its comprehension of the task rule, dynamically adapted the value assigned to stimulus.\\Reinforcement learning models capture such dynamic, parameterizing the learning functions. We proposed a learning-forgetting model, and we focused on the crucial terms for RPE signals, namely the uncertainty to get the reward and the prediction error. The prediction error, called $\delta$ in the model, was nothing but the mathematical difference between the expected reward value and the actual reward; the uncertainty, $\alpha$, was a time-dependent component, modulated by recent predictions and the prediction error $\delta$. This component mimicked the uncertainty of the animal to get the reward, and its value was high at the beginning of the task and decreased ad the animal learnt the rule, to raise up again at the beginning of the reversal phase.\\%The prediction error was monotonically increasing with the difference between the reward and the expected reward value, it was positive when a not expected reward occurred and negative when vice-versa an expected reward did not occur. 
    Conversely, RPE signals in dopamine neurons are such that neuronal activity increases monotonically after the stimulus onset with the probability to get the reward, as consequence of the increase of the certainty of the animal to get the reward when it learnt the task; meanwhile at the reward delivery time, the neural activity decreases as the ability of the animal to predict the reward increases (see \hyperref[chap:Overview]{~Chapter \ref*{chap:Overview}}). In other words, during learning the peak of neural activity shifts back from the reward retrieval time to the stimulus onset.\\Based on this knowledge we assumed that, if an assembly-pair conveyed RPE signals, its activity anti-correlated with the uncertainty in the stimulus window, and correlated with the prediction error in the reward window.\\This was assessed with two Poisson linear regression of the assembly-pairs activity on the uncertainty ($\alpha$) in the CS window and on the prediction error ($\delta$) in the US window. The regression coefficients distributions confirmed that SPN-DAN assembly-pairs specifically conveyed RPE signals; this signals were not found in FSN-DAN assembly-pairs, that could instead represent motivational salience or hedonic signals. In conclusion we provided a specific coding mechanism of how assignment value and reward prediction error signals are formed and encoded in VS-VTA assemblies. 
\end{itemize}
  