\chapter{Discussion}
\label{chap:Conclusion}
In the here presented work, I examined the interregional assembly activity between ventral striatum (VS) and ventral tegmental area (VTA) during reinforcement learning. The purpose of this work, was to understand the interaction between the two brain regions and specifically the task-related activity of these assemblies. Towards, to detect assemblies, I employed a recently developed algorithm that I will discuss initially. Based on the assembly detection and characterization, I will then discuss how I investigated whether the assembly activity is related to reward prediction error signaling.
\subsubsection{Methodological discussion on cell-assembly detection method (CAD)}
The nature of cortical representations is central for an understanding of how memory and cognitive operations are implemented by the brain. The scientist Donald Hebb outlined a comprehensive biological theory of psychological function (\cite{Hebb}). His theory relates psychological phenomena as learning, perception, motivation, and emotion to anatomical structures and to physiological processes in the brain. The connection made by Hebb$'$s theory was truly ground breaking when it was published and it defined the program of theoretical neuroscience, that is prevailing to the current day. Hebb built his theory on the definition of a new concept that he called the cell-assembly. A cell assembly refers to a group of neurons organized as a single, functional unit. The stimulation of a constituent neuron results in the activation of the entire group. Under this hypothesis, whenever a subject repeatedly faces a specific cognitive task, the assemblies processing such task will repeatedly activate. However the terms lacks of stringent definition, and it has loosely used to denote anything from the precise zero-phase-lag spike synchronization in a defined subset of neurons (\cite{Abeles}, \cite{Roelfsema}, \cite{Diesmann}, \cite{Harris2003}) to temporally coherent changes in average firing rates on larger time scales (\cite{Goldman}, \cite{Durstewitz}); meaning that cell assemblies may vary in the precision of the temporal coordination of their units, generating patterns with temporal coordination ranging from the millisecond precision to broader rate modulations (\cite{RussoDurstewitz}). The detection of cell assemblies from neural data is based on the idea that each an assembly it reveals as a repetitive activity pattern in the data; and thus it is identifiable as a supra-chance recurrent pattern. However as the number of the recorded units increases the number of assembly patterns to test provokes the combinatorial explosion. Moreover, non-stationarities present in neural data can affect the reliability of the test if they are not account for.\\To overcome some of the challenges outlined above, most techniques limit the search for assembly patterns to one or the other specific time-scale or coordination (\cite{Torre}, \cite{Gruen} \cite{Tavoni}, \cite{Billeh}). Such temporal resolution is, however, a core feature of the assembly coding and it can vary depending on the brain region and the cognitive function that is performed in a specific task.\\In this work I applied a cell assembly-detection method, developed by \citeay{RussoDurstewitz}, which is able to detect assemblies of synchronously and sequentially active units at arbitrary time scales, enabling so the investigation of the time scales and the inter-units lag activation involved in the detected patterns of spikes. CAD is based on a fast parametric test statistic which allows the unsupervised scanning and statistical testing of a large number of configurations. An efficient a-priori algorithm recursively agglomerate units into larger groups allowing the detection of assemblies composed by an arbitrary number of units. By binning the time series at different bin sizes and reducing broader temporal scale processes to the sum of parallel Bernulli sub-processes CAD is able to test assemblies at arbitrary time scales. Finally thanks to a difference statistic the method is resistant to non-stationarity in the time series, avoiding the detection of false positive. Thanks to these methodological advances the method is not only able to detect a large variety of assembly constellations, avoiding the a priori selection of a specific theoretical hypothesis, but infers for each specific dataset the relevant time scales of the information encoding.\\A direct comparison on ground truth non-stationarity data between CAD and PCA-based methods (\cite{Lopes}, \cite{RussoDurstewitz}), revealed how the correction for non-stationarity is critical in the detection performance. Indeed, the presence of non-stationarities massively reduced the performance of PCA-based methods, both reducing the assembly detection rate and increasing the false discovery rate.\\Furthermore CAD, in contrast to other recent methods (\cite{Watanabe2019}), can establish the identity of the units composing a cell assembly; this property was in fact crucial for the study of VS-VTA interactions, allowing to assess different coding features for different assembly-pair types.\\
Finally, assembly mining methods, CAD included, aim typically to detect patterns of coordinated increase in spikes/firing rate. Therefore, if a recurrent pattern is composed of both an increase and a decrease in rate of two sets of units, only the excited set would be detected as an assembly. 

\subsubsection{Interregional assembly activity during reinforcement learning}
\textbf{Nature of detected assemblies.} In line with the above considerations on CAD, the here presented analysis was only sensitive to assembly pairs where both participating units displayed excitatory responses. SPNs are inhibitory projection neurons. This means that in the detected assembly-pairs with leading inhibitory units, like directional SPN-DAN assembly-pairs, the DAN activation following the SPN activation was not necessarily caused by direct monosynaptic connections, but rather as the consequence of a functional interaction that most probably includes interspersed units and disinhibition. Alternatively, as is the case for DAN with rebound burst features, burst firing can occur, after a first transient inhibition, in response to firing of presynaptic inhibitory neurons. 

\subsubsection{Cell-types underlying interregional assemblies} 
Both ventral striatum and VTA contain different cell types. Knowing the cell types that constitute the assemblies can help to interpret their potential functional implications. Also, importantly, one may predict that certain cell types form preferentially assemblies that encode specific task related events. Within the ventral striatum, also comprising the ventral pallidum, we found two cell types based on their baseline firing frequencies. One cell type was striatal projection neurons (SPN) with low firing frequencies (\cite{Kravitz}) and the other one was fast spiking neurons (FSN) compatible with ventral pallidum units (\cite{Heimer1982}). The VTA neurons were classified based on a different approach. Neurons were clustered according to significant activations to reward with transient or persistent activations in the stimulus and reward time window as previously established by Uchida and co-workers (\cite{Uchida}). This classifications was confirmed for DAN by optogenetic tagging in DAT:Cre mice expressing ChR2 selectively in DAN. Based on this classification approach we found two cell types in VTA representing the majority of recorded cells: the first cell-type were DANs and the second were gabaergic (GABA) neurons.\\\\
Assemblies were examined between these dominant cell-types of ventral striatum and VTA. In this data set I applied the CAD method, to detect assemblies of synchronously ($lag=0$) and sequentially ($lag\neq0$) active units at arbitrary time scales. Using $\chi^2$ statistics, I could show that different cell-types preferentially formed functional assemblies. In particular, SPN-DAN and FSN-GABA assemblies showed high tendency to agglomerate in together assemblies. Yet, I also observed a larger group of significant FSN-DAN assemblies. For the further analysis, I focused mainly on two assembly types: SPN-DAN and FSN-DAN. The main motivation for this selection was the focus of this work on reward prediction error signaling where DAN play the central role.\\\\ 
\subsubsection{Temporal organization of assembly activity}  
The detected assemblies had very different temporal precision. Assemblies of temporal precision at the scale of few tens of milliseconds were only detected in intra-regional assembly within either VS or VTA, while assemblies of lower temporal precision were detected across VS-VTA units. The temporal precision of VS-VTA assemblies displayed a bimodal distribution with peaks around hundred milliseconds and one second. I focused on the more precise temporal scale of VS-VTA assemblies, firstly, not to interfere with the characteristic temporal scales of the experiment such as the stimulus duration and, secondly, because the reward prediction error signals typically involve fast temporal scales in the range of few hundred milliseconds.\\\\
\subsubsection{Task related activity}  
.  To better understand the relation between assembly activations and the task, I analyzed the assembly activation in three task-relevant time windows. The time windows were each of half a second. The first window started directly from stimulus onset to reveal short latency stimulus responses as well as evolving signals with few hundred millisecond delays following stimulus onset. The second window was chose in the half second before reward delivery. These two time windows thus contained most of the activity related to stimulus response and reward anticipation. These time windows had also to be chosen in this way because the time from stimulus onset to reward had been varied in the experiment. Therefore, some sessions have a partial overlap between the two windows, while in others there is a gap between the two windows.  Yet, by choosing the windows in this way, I was able to perform the analyses across sessions. Finally, I used a third window starting from reward delivery on; in unrewarded trials, an expected reward time was chosen, assuming that the animals would have expect the reward after the third lick, since the task was conditioned to animals performing three licks to get the reward. Using this approach, I could show that assemblies composed of different cell types displayed distinct task-related activation patterns.\\
SPN-DAN assembly-pairs were active at few hundred milliseconds after the onset of the stimulus and remained active for several hundred milliseconds. Importantly, SPN-DAN assemblies were preferentially activated by the rewarded stimulus, but not by the non-rewarded. This latter observation suggests that the assemblies could be involved in coding for the predicted value of the stimulus. Of note, only a smaller fraction was active also at the time of the reward retrieval.\\
Conversely, FSN-DAN pairs activated mainly shortly after the onset of the stimulus. Their activation was transient and relatively unselective for the stimulus, meaning that many assemblies were activated both by rewarded and non-rewarded stimuli. In contrast to SPN-DAN assemblies, those among FSN-DAN also activated sharply around reward delivery. These activation patterns suggest that the task-related coding of assemblies containing FSN differs from those comprising SPN in that the assemblies with pallidal contribution code for hedonic rewards and unspecific stimulus salience (relevance), while those involving striatal units serve more specific functions related to reward prediction related to stimulus presentation.\\\\
\subsubsection{Directionality of assembly activity} 
The activation of the underlying units within an assembly can be synchronous and sequential. If sequential, the lag between the two unit activities can reveal directionality. Indeed, dividing the assemblies according to the underlying cell-types revealed that assemblies composed of SPN and DAN neurons were directional with SPN leading DAN. It is worth to note that the directionality was even more consistent when only optogenetically tagged DAN were included compared to inclusion of all DAN characterized by function criteria. Importantly the here observed directionality is functional. Functional directionality means that the units in assemblies do not have to be directly connected by a synapse. Indeed, the SPN-DAN communication may occur both directly and relayed through interspersed neurons (\cite{Ikemoto}). The directionality that was found in SPN-DAN assemblies, but not in FSN-DAN assemblies, suggests that VS could inform VTA about task relevant information. \\\\
\subsubsection{Precision and evolution of assembly activity} 
SPN-DAN assemblies display a high level of variability in their trial-by-trial activation.  It appears important to not here that the sparse firing to stimuli of SPN alone displays a high variability. It is therefore likely that many SPN sum up to drive DAN firing. To further examine the learning dynamics in the assemblies, we modelled the reinforcement learning and examined in how far the assembly activations would encode for RPE.\\\\
\subsubsection{Reinforcement learning model}
In reinforcement learning, Rescorla-Wagner based models implement the main component of the biological RPE signal (\cite{Schultz2016}). This RPE computation is performed as the difference between the actual reward value and the expected reward value, which is adapted trial-by-trial according to error made in the previous trial, thus mimicking the dynamics of the stimulus-outcome association learning.\\In the here presented work, I used a reinforcement learning model (Q L-F) to parameterize learning, on which later I regressed the assembly-pair activity. Q L-F was a hybrid Rescorla-Wagner model with Pearce-Hall update mechanism, which implies a dynamic learning component (\cite{Koppe}, \cite{Li}, \cite{Costa}); a2015); and this model also contained a time dependent forgetting component, which accounted for the update of the unchosen option (\cite{ItoDoya1}, \cite{Katahira}). The importance to the account for a a dynamic learning component was highlighted in rats experiment in  \citeay{Funamizu}, where the authors compared the inference of fixed learning rates at the beginning and the end of the task. They divided learning sessions into two parts: the first part contained the first 10 trials and the second part contained the last 10 trials of the session. The learning rates of the model were independently set to achieve maximum likelihood in each first and last part. Learning rates associated with the first 10 trials were significantly higher than those of the last 10 trials, suggesting that rats utilized time-varying learning rates.\\\\I assumed that mice utilized similar learning dynamics in our task; thus I employed a dynamic learning parameter, mimicking the uncertainty of the animal about the possible outcomes. In Q L-F, the forgetting term is also dynamic; assuming that the animals inferred the value related to the unchosen action while taking a specific action.\\\\Importantly the dynamic forgetting term introduced in Q L-F significantly improved the behavioral fit; suggesting that in the inference of the unchosen option, the mice utilized dynamic forgetting parameters.\\\\To estimate whether the model described the data well, Q L-F was compared with three other models not including the dynamic forgetting parameter. Q L-F was the best model according to two criteria used for model comparison. The first option used is the likelihood-ratio test (LRT), this test it is used in cases in which the models to compare have different number of parameters and the model with more parameters is reducible to the simpler model by using some parameter constraints. In this case the models are called nested. Another option to compare models is the Bayesian information criterion (BIC). BIC is used in cases in which the models to compare had the same number of parameters. I used LRT to compare Q L-F and its related nested models, and I used BIC when Q-LF and the models in comparison had the same number of parameters. According to LRT and BIC Q L-F resulted way far to be the model which best approximates the animals$’$ performance. However, since BIC suffers of some limitations such as  non-selection for relevant parameters for use in model construction, I am planning to implement in future the Bayesian model comparison, as criterion to compare the models, which automatically includes a penalty for including too much model structure.\\In Q L-F, two actions $"$lick$"$/$"$no-lick$"$ and two states Cs+/Cs- corresponding to the rewarded/unrewarded stimulus, were implemented. In this way, the lick is considered an instrumental action, rather than an impulsive action; our task was indeed such that the animal had to learn to lick at the rewarded odor presentation and to not lick at the unrewarded odor; only when both actions of the task were well performed the animal reached the performance criterion. Here, further extensions of the model can be imagined. A recent work (\cite{SchultzMot}) showed that in go/no-go tasks, the performance reflects the balance between impulsive and instrumental components of behavior. The behavior may thus be decomposed in two responses: a primary lick response, defined by a sharp early peak immediately after stimulus onset, which correspond to the impulsive lick, and a broad, multi-peaked secondary response, which corresponds to the instrumental component. I assumed here that the secondary response is driven by the RPE signals. A model that could take into account the shift in behavior from the impulsive to the instrumental component would require a motivational time-component term (\cite{SchultzMot}). Accounting for motivation may further help to isolate instrumental components. Yet,  the purpose if my study was to prove generally whether the assemblies encoded for RPE components. Therefore a motivation term was not introduced here. Of note, by modelling a pure Pavlovian model, I noticed that relevant results were better described with Q L-F (see \hyperref[chap:SimpRL]{~Appendix \ref*{chap:SimpRL}} for details).\\\\
\subsubsection{Correlation with reinforcement learning model function}
After evaluating which model best approximated the animals behavior, I focused the further analyses on the crucial terms for RPE signals. The first term is the uncertainty to get the reward and the prediction error. The second term is the prediction error, called $\delta$ in the model, with $\delta$ being the mathematical difference between the expected reward value and the actual reward. The uncertainty, $\alpha$, is a time-dependent component and is modulated by recent predictions and the prediction error $\delta$. $\alpha$ mimicked the uncertainty of the animal to get the reward, and its value was high at the beginning of the task and decreased as the animal learnt the rule, When the reward contingencies switched in the reversal phase, $\alpha$ increased again.\\\\Conversely, RPE signals in DAN are such that neuronal activity increases monotonically after the stimulus onset with the probability to get the reward as a consequence of the increase of the certainty of the animal to get the reward when it learnt the task. Meanwhile, at the moment of reward delivery, the neural activity decreases as the ability of the animal increases to predict the reward (see \hyperref[chap:Overview]{~Chapter \ref*{chap:Overview}}).In other words, the peak of neural activity shifts back from the reward retrieval time to the stimulus during learning.\\\\Based on this knowledge I assumed that, if an assembly-pair conveyed RPE signals, assembly activity should anti-correlate with the uncertainty in the stimulus window, and correlate with the prediction error in the reward window.\\\\This was assessed through two regressions of the assembly-pairs activity on the uncertainty about the outcome ($\alpha$) in the CS window and on the prediction error ($\delta$) in the US window. Since the activity of the recorded assemblies followed the Poisson distribution, I employed a generalized linear model with logarithm link function (Poisson regression), which constitutes the generalization of ordinary linear regression for response variables that have error distribution models following the Poisson distribution.\\\\After transformations (see \hyperref[sec:Regression]{~Chapter \ref*{sec:Regression}}), the regression coefficients of the Poisson regression can be interpreted as the percentage increase of the expected counts (assembly activity) when the covariate variable ($\alpha$ or $\delta$) increases of 1.\\\\Significance of regression coefficients ($\beta$) was assessed with t-statistic. The t-test performed to assess $\beta$ significance assumes normality and independence of the residuals of the regression model. The progressive learning from trial to trial results in strong autocorrelation in the data. As a consequence, regressions on time series often violate the assumption of independent residuals. It is good practice to control the residuals autocorrelation before proceeding with the t-test. For our datasets I visually inspected the residuals autocorrelation and confirmed no temporal dependence as it may be already captured by the model. Nevertheless, as further control, I am planning to confirm the significance of the $\beta$ coefficients with a bootstrap test performed with phase randomization (\cite{Mokeichev}). Phase randomization consists in decomposing the data into frequency components, shifting randomly their relative phase, and then summing them back to obtain surrogate time series with power spectrum (and therefore autocorrelation) identical to that of the original data.\\\\Employing the above described approach, I found that the distributions of significant $\beta$ support that SPN-DAN assembly-pairs specifically conveyed RPE signals. Strikingly, FSN-DAN assembly-pairs did not correlate with RPE signals. These findings suggest that specific coding mechanisms exist in assemblies formed between striatum and dopaminergic neurons for assignment of value and formation of RPE signals during learning of stimulus-outcome association. \\\\
\subsubsection{Biological implicatons}
In summary, we have observed that while SPN-DAN assemblies were selective to the rewarded stimulus and correlated with the RPE, FSN-DAN did not correlate and were also largely non-selective for rewarded and non-rewarded stimuli. These observations have a series of implications.\\\\
\textbf{Motivational salience and reward coding in FSN-DAN assemblies}
Like the adjacent striatum, the ventral pallidum receives dense dopaminergic inputs. Besides this similarity, however, the two regions have different network architectures and different coding properties (\cite{Heimer1997}, \cite{Tachibana2012}). The ventral pallidum is a major input-output structure of the basal ganglia (\cite{Heimer1997}). It receives projections from areas including the ventral striatum, the olfactory cortices and other regions (Haber and Knutson, 2010). In vivo recordings have shown that ventral pallidum neurons encode motivation of a stimulus (\cite{Tachibana2012}, \cite{TianHuang}) and transmits information to multiple brain regions involved in motor control and motivation (Haber and Knutson, 2010). Pallidal neurons thus encode information related to the expected or incentive salience of stimuli (Richard et al., 2018; \cite{TianHuang}, Tindell et al., 2006). Consequently, activation of pallidal neurons can be both reinforcing or aversive (Faget et al., 2018; Knowland et al., 2017) and drive reward seeking behavior (Humphries and Prescott, 2010, \cite{Root}, \cite{Berridge}). It is therefore maybe not surprising that FSN-DAN assemblies displayed sharp transient activations to obtained rewards. These assemblies further responded unselectively to any stimulus, be it Cs+ or Cs-, compatible with incentive salience of generally task relevant stimuli. The here for the first time investigated interregional ventral pallidum – VTA assemblies may help to understand why longstanding debates exist on what is encoded when monitoring VTA neurons in isolation (\cite{Redgrave}). FSN-DAN and SPN-DAN assemblies share both DANs, but serve different functions. Therefore, the function of a neuron may be better understood in its interaction in assemblies. This becomes evident when looking at the other assembly type comprising also DAN.\\\\
\textbf{Prediction error signaling in SPN-DAN assemblies}\\
DAN activity reflects RPE signals, but it is broadly agreed that VTA does not generate these signals (\cite{Schultz2016}). Different studies suggested that the RPE in DAN may be driven by inputs from striatal and cortical reward neurons (\cite{Cai1}, \cite{PadoaSchioppa}). The initial DAN bursts release phasic dopamine as a reinforcement signal to cortico-striatal circuits (\cite{Redgrave}, \cite{Schultz2002}, \cite{Ungless2004b}, \cite{Wise2004}, \cite{WatabeUchida}). Cortico-striatal circuits encode different features of stimuli (\cite{Rolls}, \cite{Yeshurun}). In these circuits, value and identity information are dynamically encoded by populations of neurons with excitatory and inhibitory responses that evolve over time in response to the stimulus (\cite{Averbeck}, \cite{Bakhurin}, \cite{Laurent}). While some of the primary sensory areas code mainly for the identity of the stimulus (Gottfried, 2010; Howard et al., 2009; Kadohisa and Wilson, 2006; Stettler and Axel, 2009), the prediction signal has been extensively shown to be represented in the ventral striatum in human imaging studies and recordings from many other species (\cite{Schultz2000}, \cite{Pagnoni}, \cite{Berridge2003}, \cite{ODoherty2004} ). In particular, neuronal activity in the ventral striatum is modified when subject learns to predict future rewards from sensory cues (\cite{Schultz2000}, \cite{Pagnoni}, \cite{Radua} ). Theoretical and experimental work has suggested that ventral striatum may be an important source of prediction signal, particular to DAN in the VTA (\cite{Daw2005}, \cite{ODoherty2004}, Seymour et al., 2004; \cite{Takahashi2016}, Willuhn et al., 2012). Indeed, we observed a clear directionality with SPNs preceding the firing of DAN by a lag of up to few hundred milliseconds. It is interesting to note that among basal ganglia and midbrain neurons, SPN-DAN assemblies were the only ones in our sample with clear directionality. SPN-DAN assemblies were selective for Cs+. Together these data strongly support that after stimulus-outcome learning, assembly activations to Cs+ in SPN-DAN represent the main component of the RPE. The main component is parametrized by the RPE function and by the dynamics of the uncertainty of the stimulus-outcome contingency. Based on broad evidence (\cite{Fiorillo}, \cite{Schultz2016}), the main component is anti-correlated with uncertainty of the future reward and correlation with the RPE function. Our SPN-DAN assemblies indeed anti-correlate with uncertainty and correlate with the RPE; supporting that the directional assembly activity with DAN following SPN encode the value prediction signal. The encoding of the value prediction signal was however not expressed in assemblies of ventral pallidal neurons also projecting to DAN, suggesting that the ventral striatal assemblies with DAN conveyed specific information on the RPE. The SPN-DAN assemblies thus constitute biological implementations of the crucial error term for reinforcement learning according to the Rescorla–Wagner model and temporal difference reinforcement models (Montague et al., 1996). Such a signal is appropriate for mediating learning and updating of reward predictions for approach behavior and economic decisions (Schultz, 2016). Probably the most important potential that utility has for neuroscience lies in the assumption that utility provides an internal, private metric for subjective reward value. This utility as an internal value reflects individual choice preferences in social interactions (\cite{Ungless2004b}, Walum and Young, 2018), formation of drug addiction (Hyman et al., 2006) or psychoses (Kapur, 2003).

