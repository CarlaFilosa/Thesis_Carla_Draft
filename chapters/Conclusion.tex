\chapter{Conclusion}
\label{chap:Conclusion}
{\color{red}Subjects learn to assign value to stimuli that predict outcomes. Novelty, rewards or punishment evoke reinforcing phasic dopamine release from midbrain neurons to ventral striatum that mediates expected value and salience of stimuli in humans and animals. It is however not clear whether phasic dopamine release is sufficient to generate distinct engrams that encode salient stimuli in ventral striatum that may inform dopaminergic neurons to respond with a prediction signal. We addressed this question in awake mice. Evoked phasic dopamine induced plasticity selectively to the population encoding of coincidently presented stimuli and increased their distinctness from other stimuli. Phasic dopamine thereby enhanced the decoding of previously paired stimuli and increased their perceived salience. 
During reinforcement learning such dynamics progressively generated functional directional assemblies between striatal projection neurons and dopaminergic neurons. These findings provide a network coding mechanism of how dopaminergic learning signals promote value assignment to generate an assembly prediction code to dopaminergic midbrain neurons.
The mesolimbic dopamine pathway comprising the ventral tegmental area (VTA) and projection terminals in the ventral striatum (VS) has been identified as a critical neural system involved in processing both the rewarding and aversive behavioral effects of rewarded and unrewarded stimuli.\\Neuronal models of reinforcement learning assume interactions of midbrain dopaminergic neurons and striatum to compute the differences between anticipated and received outcomes, this signal corresponds to the definition of reward prediction error (RPE) in reinforcement learning model (\cite{Schultz2001}, \cite{Schultz2002}, \cite{Fiorillo}, \cite{Eshel1}, \cite{Pagnoni}, \cite{Radua}, \cite{Takahashi2016}). However, how these computations are implemented in VS-VTA neural circuits is not fully understood. The VTA receives inputs from many different brain regions and cell-types, but what each of these inputs contributes to RPE computation is unclear. Recently Watabe-Uchida and colleagues have shown that these input neurons show a wide range of different response profiles to cues and rewards (\cite{TianHuang}).\\In this work we propose an in depth study on the formation of prediction error signals in interregional assemblies during reinforcement learning. On this purpose we record dual site simultaneous electrophysiological in-vivo data from VS (including Pallidum) and VTA. Details of the task and the data set are presented in \hyperref[sec:Dataset]{~Section \ref*{sec:Dataset}} and \hyperref[sec:MatAndMet]{~Section \ref*{sec:MatAndMet}}. On this data set we apply a cell assembly detection algorithm (\cite{RussoDurstewitz}), that will be presented in\hyperref[chap:AssemblyMethod]{~Section \ref*{chap:AssemblyMethod}}.
The novel statistical approach is free to detect spike patterns at any time scale and coordination enabling so the investigation of the time scales and the inter-units lag activation involved in those interregional interactions.\\In\hyperref[chap:AssemblyAnalysis]{~Chapter \ref*{chap:AssemblyAnalysis}} we present the cell-assembly analysis intended to understand the nature of VS-VTA direct and indirect pathways.\\One of the most puzzling question about VS-VTA interactions is if there exists a preferred direction in which the prediction error signal is encoded. Restricting the analysis of assemblies at level of assembly-pairs we investigate the directionality between VS-VTA interactions through the inter-unit lag activation. Using the algorithm at level of inter-regional pairs the lag in activation between two units, one in VS and the other in VTA, is nothing but the lag in activation between the regions. Our nomenclature is such that a positive lag means that VS is prior in activation, a negative lag, vice-versa, means that VTA is preceding the activation of VS. VS predominantly leads VTA in detected assembly-pairs.\\Moreover interregional assembly-pairs show a bimodal time scale distribution, such bimodality is solely present in VS-VTA pairs and it does not emerge in intraregional pairs. Looking at the assembly-pairs activity it emerges that different time scales and directionalities dissect different activity patterns, in particular directional assembly-pairs with VTA following VS in shorter time scale show activity patterns in agreement with prediction error encoding (\cite{Tobler2003}, \cite{Nomoto2010}, \cite{Schultz2016}).\\Taking advantage of well defined neuron typologies classifications both in VS and VTA, we further investigate the specific cell-type composition of the assemblies exhibiting directionality. Interestingly only assembly-pairs formed by putative striatal projection neurons (pSPN) and dopamine neurons (pDAN) are directional in the direction of VS leading VTA.\\Thus, considering the dissection in different activity patterns brought by different time scales and directionality, we assume that different assembly-pair types are diversified in task related activity.\\We examine the task related patterns of different assembly-pair types in three windows of interest, defined from crucial moments in the task proposed, the stimulus and the reward. Significant assembly-pairs activity will be assessed by Friedman test.\\Different assembly-pairs types show different activity patterns in response to external potentially rewarded stimuli. This difference reflect different coding and encoding features. We make in this thesis the hypothesis of high specialized coding of assembly-pair types, specificity that cannot be detect at single units level.\\Indeed, based on broad evidence (\cite{Eshel}) dopamine neurons share common response functions in prediction coding to guarantee robust information coding inasmuch each dopamine neuron contributes fully to the reward prediction error. However, whether different neuronal interactions involving dopamine neurons specialize in different aspect of reward prediction error remains still elusive.\\In the last years it has been shown that reward prediction error is consisting of different components (\cite{Nomoto2010}, \cite{Fiorillo2013b}, \cite{Schultz2016}). The first, detection component, reflects a unspecific response to stimulus, in order to detect it, regardless its association with the reward. After this phase, the stimulus is identified in order to assign to it a value, allowing the animal to predict the reward. This second component of prediction error, also called the main component, constitutes biological implementations of the crucial error term for reinforcement learning according to the reinforcement learning models.\\We hypothesize that the main component signal is formed specifically by SPN-DAN pairs, whilst FSN-DAN pairs could be in part involved in motivational salience at the odor onset, reflected in the detection component of prediction. Observing FSN-DAN pairs from up close they seem to reflect motivational and emotional aspects that cannot, or at least can only partially, be included in prediction error coding.\\We build these hypotheses starting from assembly-pair types task related patterns, precisely. SPN-DAN assembly-pairs response show resemblance to reward prediction error signals, that is not equally found in other assembly-pair types. First because the time scale of SPN-DAN interactions and the activation profile suggest that specifically these pairs are involved in the main component of prediction error. Detailed discussion will be presented in\hyperref[sec:TaskResp]{~Section \ref*{sec:TaskResp}} and\hyperref[sec:FalseAlCorrRej]{~Section \ref*{sec:FalseAlCorrRej}}.\\From the evolution in trials of the assembly-pairs response, it is clear that the assembly get modified by the high dynamic of task, proper of the learning process. This dynamic cannot be replicated by the study of activity patterns, for this reason we model a reinforcement learning-forgetting model, that will be presented in\hyperref[chap:RLModel]{~Chapter \ref*{chap:RLModel}}. Crucial terms of the reinforcement learning are the uncertainty of the animal to get the reward and the reward prediction error, those terms evolve during the task as the animal learns and become more experience. The evolution of these components allows the animal to assign a new value to the stimulus presented. Both terms, uncertainty are included in our model as time dependent terms.\\Reward prediction coding signals in dopamine neurons vary according to the probability to get the reward, which is often related to the uncertainty (\cite{Schultz1992}). Dopamine neurons in VTA as well as neurons in VS modify their activity in function to the difference between received and expected outcomes (\cite{Fiorillo}).\\Based on this knowledge, reward prediction error signals anti-correlate with the uncertainty of the animal to get the reward and correlate with prediction error.\\Thus, if SPN-DAN assembly-pairs specifically encode prediction error signals, we expect their activity to anti-correlate with the uncertainty term of the model and to correlate with the prediction error.\\The study of correlations is conducted in\hyperref[sec:Regression]{~Section \ref*{sec:Regression}}. We model two linear Poisson regressions and we regress out the uncertainty and the prediction error. Our SPN-DAN assembly-pairs indeed anti-correlate with the uncertainty and correlate with the prediction error term, furthermore such correlations are not found in other assembly-pair types, from which we can conclude that assembly-pairs with SPN projecting on VTA dopamine neurons specifically encode reward prediction signals.}
