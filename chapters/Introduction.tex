\chapter{Introduction}
\label{chap:Introduction}
%\section{Motivation}   
%\label{sec:Motivation}
The mesolimbic dopamine pathway comprising the ventral tegmental area (VTA) and projection terminals in the ventral striatum (VS) has been identified as a critical neural system involved in processing both the rewarding and aversive behavioral effects of rewarded and unrewarded stimuli. In these functions the brain performs simple arithmetic: it compares the expected and the received outcomes and computes the differences between the two. In other words after receiving the outcome, it computes the error made in predicting the outcome. This signal is called reward prediction  error (RPE): being essential to learning, to reward maximization, and to guide reward-related behavior, RPE has been widely investigated in last decades. In dopamine neurons RPE signals are characterized by activations following primary food and liquid rewards, and visual, auditory and somatosensory reward-predicting stimuli. The reward-related activation is usually preceded by a brief detection component before the proper valuation of stimulus; which evolves in time in the valuation component where the stimulus is fully appreciated (\cite{Schultz2001}, \cite{Schultz2002}, \cite{Fiorillo}, \cite{Eshel1}, \cite{Pagnoni}, \cite{Radua}, \cite{Takahashi2016}, \cite{TianHuang}). In this section we present the state of the art of the current knowledge of ventral striatum (VS) and ventral tegmental area (VTA), needed for the study of VS-VTA interaction.\\In VTA, dopamine neurons fire phasically (100-500 ms) after unpredicted rewards or cues that predict reward. Their response to reward is reduced when a reward is fully predicted (\cite{Uchida}). %Furthermore, their activity is suppressed when a predicted reward is omitted. From these observations, previous studies hypothesized that dopaminergic neurons signal discrepancies between expected and actual rewards (i.e., they compute RPE).
The uncertainty about the reward outcome is critical in the measure of information and in assessing the accuracy of predictions. The uncertainty is determined by the probability P to get the reward, and its maximal at $P=0.5$, while decreases at higher and lower probabilities.\\Fiorillo and his collaborators used distinct stimuli indicating the probability of reward, to show that the phasic activation of dopamine neurons varied monotonically across the full range of probabilities (\cite{Fiorillo}). Figure \ref{fig:probDopamine} (left) displays the dopamine neurons response to stimuli with different reward probability. These observations have defined the basis of the current knowledge on dopamine neurons, which are assumed to signal discrepancies between expected and actual rewards, in other words they are thought to compute the reward prediction error (RPE).\\Being essential to learning, since ever RPE signals picked the scientist$'$ curiosity, who dissected the evolution in time of those signals to understand the underlying nature of multiple time components of RPE. Several studies have shown that RPE signal evolves in time from unselective sensory detection to more demanding and crucial stages of identification and valuation (\cite{Tobler2003}, \cite{Nomoto2010}, \cite{Fiorillo2013}, \cite{Schultz2016}), value that is constantly adapted during the learning process by dopamine neurons (\cite{Tobler2005}). The initial component, characterized by a brief activation, occurs unselectively in response to a large variety of unpredicted events and corresponds to the large range and heterogeneous nature of potentially rewarding stimuli and object present in the environment. This component reflects the detection of stimulus, regardless its relation with the reward.\\The second component, also called main component or valuation component, defines the function of the dopamine response and reflects the evolving neuronal processing that is required to fully appreciate the value of the stimulus. Thus, at this stage the stimulus is identified and valued. Figure \ref{fig:probDopamine} (right) shows the separation between the detection salience and the valuation component of RPE signals in dopamine neurons. %In stark contrast to the simple models proposed previously, we observed that information about reward and expectation is distributed among multiple brain areas and already mixed in many individual input neurons. Our data suggest that the RPE computation is not a one-step process combining pure information about reward and expectation in dopamine neurons. Nor do dopamine neurons receive complete RPE from a specific brain area. Instead, the coexistence of input neurons encoding pure and mixed information, some of which are partial and complete RPE signals, appears to be a sign of redundant computations distributed in a complex neuronal network that ultimately converge onto dopamine neurons to construct a more complete RPE signal.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/Schultz1.png}
    \hspace{1cm}
    \includegraphics[scale=0.35]{figures/ResponseProbSchultz.png}
    \caption{\textbf{Left:} Adapted from \cite{Fiorillo}. Reward-related response of dopamine neurons. Distinct stimuli were used to indicate the probability of reward (P increasing from top to bottom). Dopamine neurons signals varied monotonically across the full range of probability. At the stimulus onset the dopamine response increased monotonically as the probability increased, at the reward time instead the dopamine response decreased monotonically as the probability increased. \textbf{Right:} Adapted from \cite{Schultz2016}. A demanding random dot motion discrimination task reveals completely separated dopamine response components. Higher response corresponds to higher reward probability (p). The initial, stereotyped, non-differential activation reflects stimulus detection and decreases back to baseline (blue zone); the subsequent separate, graded increase develops when the animal signals stimulus discrimination; it codes reward value (red zone), which in this case derives from reward probability}
    \label{fig:probDopamine}
\end{figure}
%\begin{figure}
 %   \centering
  %  \includegraphics[scale=0.4]{figures/ResponseProbSchultz.png}
   % \includegraphics[scale=0.4]{figures/Schultz2016CSMod.png}
  %  \caption{Adapted from \cite{Schultz2016}. A demanding random dot motion discrimination task reveals completely separated dopamine response components. Higher response corresponds to higher reward probability (p). The initial, stereotyped, non-differential activation reflects stimulus detection and decreases back to baseline (blue zone); the subsequent separate, graded increase develops when the animal signals stimulus discrimination; it codes reward value (red zone), which in this case derives from reward probability}
 %   \label{fig:probSchultz}
%\end{figure}
Like VTA neurons, VS neurons show as well reward-related response. In monkey experiments first it has shown that VS neurons predominantly fire in relation to the expectation of reward, regardless the movement no-movement reaction (\cite{Schultz1992}). This signals suggested that VS neurons have access to central representations of reward and thereby participate in the processing of information underlying the RPE computation.\\The stereotypical response of projection neurons in VS during learning consists in a sustained increase of activity before the occurrence of the reward delivery (see figure \ref{fig:StriatumN}).
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.22]{figures/StriatumR.png}
    \caption{Adapted from \cite{Schultz1992}. Stereotypical reward-related VS neuronal activity. Effect of delayed reward delivery in no/ no go task in monkeys. VS neurons showed sustained increases of activity before the occurrence of individual task events. VS neurons exhibit activation in relation to the expectation of reward.}
    \label{fig:StriatumN}
\end{figure}
The ventral pallidum (VP), from which we recorded fast spiking activity, is innervated by dopamine inputs from the midbrain and dopamine directly alters VP neuronal firing (\cite{Napier89}). Since 1991 VP was assumed to integrate reward-related signals carried by VTA dopamine neurons, involved in reward-motivated behavior (\cite{Napier91}). This concept was quickly expanded to encompass the idea that dopamine transmission within the VP regulates a collection of behaviors, including locomotion and cognition (\cite{Napier92}). Contrary to the well-characterized, relatively homogeneous projection neurons dominating striatum, the cellular architecture of VP is only beginning to be understood in terms of their heterogeneous cell-types, neurotransmitters, and connectivity (\cite{Heimer1997}, \cite{Tachibana2012}). In other studies we observed that VP units displayed either purely excitatory, purely inhibitory, or multiphasic excitatory and inhibitory responses to the same stimulus or across reward and unrewarded stimuli (unpublished results). For these reason, the responses of VP neurons are expected to be diverse among different VP units, probably depending on the involvement of the unit in a specific coding.\\While there is a excellent knowledge of the RPE signals expression by single units, how the RPE computations are implemented in VS-VTA neural circuits remains elusive.\\
%Previous modeling and experimental studies have shown that simple arithmetic computations may arise from a wealth of nonlinear mechanisms to transform synaptic inputs into output firing at the level of single neurons ( Chance et al., 2002; Holt and Koch, 1997; Silver, 2010 ). However, it remains unknown whether these mechanisms underlie brain computations in a natural, behavioral context.\\
%The VTA receives indeed inputs from many different brain regions and cell-types, but what each of these inputs contributes to RPE computation is unclear. 
%Recently Watabe-Uchida and colleagues have shown that these input neurons show a wide range of different response profiles to cues and rewards (\cite{TianHuang})
Thus, understanding VS-VTA related circuits, will broaden our understanding on the underpinnings of RPE signals.\\In this work we studied the formation of prediction error signals in interregional assemblies during reinforcement learning. On this purpose we recorded dual site electrophysiological in-vivo data from VS (including Pallidum) and VTA, during a reversal go/no go task in mice.\\%Details of the task and the data set are presented in \hyperref[sec:Dataset]{~Section \ref*{sec:Dataset}} and \hyperref[sec:MatAndMet]{~Section \ref*{sec:MatAndMet}}.
On this data set we applied a cell assembly detection algorithm (\cite{RussoDurstewitz}). % that will be presented in\hyperref[chap:AssemblyMethod]{~Section \ref*{chap:AssemblyMethod}}.
The novel statistical approach was free to detect spike patterns at any time scale and coordination, enabling so the investigation of the time scales and the inter-units lag activation involved in the detected patterns of spikes. %\\In\hyperref[chap:AssemblyAnalysis]{~Chapter \ref*{chap:AssemblyAnalysis}} we present the cell-assembly analysis intended to understand the nature of VS-VTA direct and indirect pathways.\\%One of the most puzzling question about VS-VTA interactions is if there exists a preferred direction in which the prediction error signal is encoded. 
We focused the analysis on interregional assembly-pairs, namely assembly formed by two neurons, one in VS and the other in VTA, in this way we were able to examine the directionality between VS-VTA interactions through the inter-unit lag activation.\\%Using the algorithm at level of inter-regional pairs the lag in activation between two units, one in VS and the other in VTA, was nothing but the lag in activation between the regions. 
We found that, in interregional assembly-pairs, VS predominantly led VTA. Moreover interregional assembly-pairs showed a bimodal time scale distribution, such bimodality was solely present in VS-VTA pairs and did not emerge in intraregional pairs.\\We examined the assembly-pair activity patterns of pairs with different time scales and directionalities. It emerged that different time scales and directionalities segregated different activity patterns. Specifically, in more precise time scale, directional assembly-pairs with VTA following VS showed excitatory responses following reward-predicting stimuli, in agreement with prediction error encoding.\\Taking advantage of well defined neuron types classifications both in VS and VTA, we further investigated the specific cell-type composition of the assemblies exhibiting directionality. Interestingly only assembly-pairs formed by putative striatal projection neurons (pSPN) and dopamine neurons (pDAN) were directional in the direction of VS leading VTA.\\Thus, we looked at the task related activity patterns of different assembly-pair types; and we expected that, being directional, SPN-DAN assembly-pairs could exhibit RPE response.\\Indeed, different assembly-pairs types showed different activity patterns in response to external potentially rewarded stimuli. The segregation reflected different encoding features in different assembly-pair types.\\In particular, SPN-DAN assembly-pairs were mainly activated by the rewarded stimulus, and only a small fraction ($\sim12\%$) was activated by both stimuli. The activation started few hundred milliseconds after the stimulus onset and remained high for few hundred milliseconds ([100,400] ms). SPN-DAN activity pattern suggested that those pairs conveyed the valuation component of RPE signals (\cite{Tobler2003}, \cite{Nomoto2010}, \cite{Schultz2016}). Conversely, FSN-DAN assembly-pairs responded indistinctly to both stimuli, either showing a brief and phasic activation at the stimulus onset or being inhibited by one or both stimuli; these signals suggested that FSN-DAN pairs were involved in motivational and/or hedonic signals. Hence, we putted forth the concept that the assembly-pairs specialize in different aspects of the learning-related coding.\\%\\Detailed discussion will be presented in\hyperref[sec:TaskResp]{~Section \ref*{sec:TaskResp}} and\hyperref[sec:FalseAlCorrRej]{~Section \ref*{sec:FalseAlCorrRej}}.\\
So far the description presented barely considered the dynamic of the learning process. In fact, reward prediction coding signals in dopamine neurons varied according to the probability to get the reward, which was often related to the uncertainty (\cite{Schultz1992}). Dopamine neurons in VTA as well as neurons in VS modified their activity in function to the difference between received and expected outcomes (\cite{Fiorillo}). In similar way, far from being static, the assembly-pair activity modified itself trial by trial, reflecting the dynamic of the learning.\\This dynamic could not be replicated by the study of activity patterns, for this reason we modeled a reinforcement learning model. Crucial terms of reinforcement learning are the uncertainty of the animal to get the reward and the reward prediction error; the first is high when the animal is unsure about the outcome, and decreases as the animal becomes expert; the latter term reflects the ability of the animal to predict the reward: as the animal learnt is supposed to be able to predict the future outcomes. Both the aforementioned terms were modeled as time evolving components, in such a way that we could take into account the fact that, during the task, the animal had to assign and re-assign new value to the presented stimulus.\\Based on broad knowledge, reward prediction error signals are thought to be anti-correlated with the uncertainty of the animal to get the reward and correlated with the prediction error term of the Rescorla-Wagner models.\\Thus, if SPN-DAN assembly-pairs specifically encoded prediction error signals, we expected their activity to anti-correlate with the modeled uncertainty ($\alpha$) and to correlate with the modeled prediction error ($\delta$).\\We modeled two linear Poisson regressions and we regressed the assembly-pairs activity on $\alpha$ and $\delta$. Our SPN-DAN assembly-pairs indeed anti-correlated with the uncertainty and correlated with the prediction error term. Furthermore we noted that such correlations were not found in other assembly-pair types, from which we could conclude that SPN-DAN assembly-pairs specifically conveyed reward prediction signals.  