\section*{Summary}
Generally, subjects aim to optimize outcomes to obtain maximal rewards. To maximize reward, predictions need to be made about future outcomes. Yet, errors occur in these predictions. A reward prediction error, then, is the difference between the received and predicted reward. Reward prediction error signals are represented in the brain in dopamine neurons in ventral tegmental area  (VTA) and evoked by reward or rewarded stimuli. These signals are essential to learning. In particular neuronal models of reinforcement learning assume interactions of midbrain dopaminergic neurons and ventral striatum (VS) to compute the differences between anticipated and received outcomes. This cross-areal interaction has however not been demonstrated.\\In this thesis, I studied the formation of reward prediction error signals in VS-VTA interregional assemblies during reinforcement learning. The work was based on in-vivo electrophysiological recordings from VS - including ventral pallidum (VP) - and VTA, during a reversal go/no go task in mice. VS/VP units were classified as striatal projection units (SPN), fast spiking neurons (FSN) and cholinergic interneurons, whereas VTA units were classified in dopamine neurons (DAN), gabaergic neurons and glutamatergic neurons.\\\\On this data set I applied a novel cell-assembly detection method able to detect assemblies of synchronously and sequentially active units at arbitrary time scales. The temporal precision of assemblies detected across VS-VTA displayed a bimodal distribution with peaks around $80$ milliseconds and $0.6$ second. Interestingly the lags of more temporally precise assemblies displayed an asymmetric distribution indicating VS leading VTA. Specifically, these directional assemblies were composed of SPN leading DAN.\\\\Analyzing the task related activity of the detected cell assembly-types, I found that assemblies of SPN and DAN were activated by the rewarded stimulus, while only few of them were activated by the non-rewarded stimulus.\\\\In contrast, assembly with FSN and DAN neurons were activated unselectively by either stimulus. Such patterns suggest that SPN-DAN assemblies were involved in reward prediction error coding while FSN-DAN assembly showed motivational and/or hedonic salience.\\\\Thus I assumed that different assembly types in the VS-VTA circuit specialized in different coding features during learning. I formally tested this hypothesis with a reinforcement model using the Rescorla-Wagner learning rule with the reward prediction error and the uncertainty to get the reward as crucial terms. Reward prediction error signals are predicted to anticorrelate with the uncertainty about the outcome at the stimulus presentation, and to correlate with the reward prediction error. The SPN-DAN assemblies indeed are anticorrelated with the uncertainty and correlated with the prediction error; thus they convey the prediction signals, crucial to learning. Furthermore I found that this encoding feature were not present in other assembly-types, supporting the hypothesis that different pathways of the VS-VTA circuit encode in different reward-related signals.