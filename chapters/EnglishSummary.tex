\section*{Summary}
Reward is an object, stimulus, situation or activity that evokes positive emotions such as pleasure and desire. Hence, during learning or in decision making processes, agents behave in such a way to maximise the reward. Maximisation of the reward requires prediction, namely information about the future. An error can be defined in the most general sense as a discrepancy between what is happening and what has been predicted to happen. A reward prediction error, then, is the difference between a reward that has been received and the reward that is predicted to be received. Reward prediction error signals are essential to learning and they are supposed to be encoded by dopamine neurons. In particular the mesolimbic dopamine pathway comprising the ventral tegmental area (VTA) and projection terminals to the ventral striatum (VS) has been identified as a critical neural system involved in processing reward prediction error.\\In this thesis we proposed a study of formation of reward prediction error signals in VS-VTA interregional assemblies during learning. The work was based on in-vivo electrophysiological recordings from VS - including ventral pallidum (VP) - and VTA, during a reversal go/no go task in mice. VS/VP units were classified as striatal projection units (SPN), fast spiking neurons (FSN) and cholinergic interneurons, whereas VTA units were classified in dopamine neurons (DAN), gabaergic neurons and glutamatergic neurons. On this data set we applied a novel cell-assembly detection method able to detect assemblies of synchronously and sequentially active units at arbitrary time scales. The temporal precision of assemblies detected across VS-VTA displayed a bimodal distribution with peaks around hundred milliseconds and one second. Interestingly the lags of more temporally precise assemblies displayed an asymmetric distribution indicating VS leading VTA. Specifically, these directional assemblies were composed of SPN leading DAN.\\Analysing the task related activity of the detected cell assembly-types, we found that assemblies of SPN and DAN were activated by the rewarded stimulus, while only few of them were activated by the non-rewarded stimulus. In contrast, assembly with FSN and DAN neurons were activated by either one. Such patterns suggest that SPN-DAN assemblies were involved in reward prediction error coding while FSN-DAN assembly showed motivational and/or hedonic salience. Thus we assumed that different assembly types in the VS-VTA circuit specialized in different coding features during learning. We formally tested this hypothesis with a reinforcement model using the Rescorla-Wagner learning rule, with the reward prediction error and the uncertainty to get the reward as crucial terms. Reward prediction error signals are predicted to anticorrelate with the uncertainty at the stimulus presentation, and to correlate with the reward prediction error term. The SPN-DAN assemblies indeed are anticorrelated with the uncertainty and correlated with the prediction error; thus they convey the prediction signals, crucial to learning. Furthermore we found that this encoding feature is not present in other assembly-types, confirming the hypothesis that different pathways of the VS-VTA circuit specify in different reward-related signals.