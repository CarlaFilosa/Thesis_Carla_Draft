\section*{Summary}
Reward evokes positive emotions such as pleasure and desire. Hence, during learning or in decision making processes, agents behave in such a way to maximise the reward. Maximisation of the reward requires prediction, namely information about the future. An error can be defined in the most general sense as a discrepancy between what is happening and what has been predicted to happen. A reward prediction error, then, is the difference between a reward that has been received and the reward that is predicted to be received. Reward prediction error signals characterize neuronal signals in dopamine neurons evoked by reward or rewarded stimuli. These signals are essential to learning. In particular neuronal models of reinforcement learning assume interactions of midbrain dopaminergic neurons in ventral tegmental area (VTA) and ventral striatum (VS) to compute the differences between anticipated and received outcomes. The nature of this cross-areal interaction is however not fully understood.\\In this thesis I studied formation of reward prediction error signals VS-VTA interregional assemblies during reinforcement learning. The work was based on in-vivo electrophysiological recordings from VS - including ventral pallidum (VP) - and VTA, during a reversal go/no go task in mice. VS/VP units were classified as striatal projection units (SPN), fast spiking neurons (FSN) and cholinergic interneurons, whereas VTA units were classified in dopamine neurons (DAN), gabaergic neurons and glutamatergic neurons. On this data set I applied a novel cell-assembly detection method able to detect assemblies of synchronously and sequentially active units at arbitrary time scales. The temporal precision of assemblies detected across VS-VTA displayed a bimodal distribution with peaks around hundred milliseconds and one second. Interestingly the lags of more temporally precise assemblies displayed an asymmetric distribution indicating VS leading VTA. Specifically, these directional assemblies were composed of SPN leading DAN.\\Analysing the task related activity of the detected cell assembly-types, I found that assemblies of SPN and DAN were activated by the rewarded stimulus, while only few of them were activated by the non-rewarded stimulus. In contrast, assembly with FSN and DAN neurons were activated by either one. Such patterns suggest that SPN-DAN assemblies were involved in reward prediction error coding while FSN-DAN assembly showed motivational and/or hedonic salience. Thus I assumed that different assembly types in the VS-VTA circuit specialized in different coding features during learning. I formally tested this hypothesis with a reinforcement model using the Rescorla-Wagner learning rule, with the reward prediction error and the uncertainty to get the reward as crucial terms. Reward prediction error signals are predicted to anticorrelate with the uncertainty about the outcome at the stimulus presentation, and to correlate with the reward prediction error. The SPN-DAN assemblies indeed are anticorrelated with the uncertainty and correlated with the prediction error; thus they convey the prediction signals, crucial to learning. Furthermore I found that this encoding feature were not present in other assembly-types, confirming the hypothesis that different pathways of the VS-VTA circuit specify in different reward-related signals.