\section*{Summary}
Reward is an object, stimulus, situation or activity that evokes positive emotions such as pleasure and desire. Hence, during learning or in decision making processes, agents behave in such a way to maximise the reward. Maximisation of the reward requires prediction, namely information about the future. An error can be defined in the most general sense as a discrepancy between what is happening and what is predicted to happen. A reward prediction error, then, is the difference between a reward that is being received and the reward that is predicted to be received. Thus, reward prediction error signals are essential to learning and they are supposed to be encoded by dopamine neurons through dopamine pathways. In particular the mesolimbic dopamine pathway comprising the ventral tegmental area (VTA) and projection terminals in the ventral striatum (VS) has been identified as a critical neural system involved in processing reward prediction error. In this thesis we proposed a study of formation of reward prediction error signals in VS-VTA interregional assemblies during learning. We recorded in-vivo electrophysiological data in VS - including ventral pallidum (VP) - and VTA, during a reversal go/no go task in mice. VS/VP units were classified in striatal projection units (SPN), fast spiking neurons (FSN) and cholinergic interneurons (CIN), whereas VTA units were classified in dopamine neurons (DAN), gabaergic neurons (GABA) and glutammatergic neurons (GLU). On this data set we applied a novel cell-assembly detection method able to detect assemblies of synchronously ($lag=0$) and sequentially ($lag\neq0$) active units at arbitrary time scales ($\Delta$). The temporal precision of assemblies detected across VS-VTA displayed a bimodal distribution with peaks around hundred milliseconds and one second. Interestingly the lags of more temporally precise assemblies displayed an asymmetric distribution indicating VS leading VTA. Specifically, these directional assemblies were composed of SPN leading DAN.\\Analysing the task related activity of the detected cell assembly-types, we found that the activation of assemblies with SPN and DAN was led by the rewarded stimulus, while only few of them were activated by the unrewarded stimulus. Whereas assembly with FSN and DAN neurons could be either activated or inhibited in response to one or both signals. Such patterns suggested that SPN-DAN assemblies were involved in reward prediction error coding while FSN-DAN assembly showed motivational and/or hedonic salience. Thus we assumed that different assembly types in the VS-VTA circuit specialized in different coding features during learning. We formally tested this hypothesis with reinforcement model using the Rescorla-Wagner learning rule, whose crucial terms were the reward prediction error and the uncertainty to get the reward. Based on broad knowledge, reward prediction error signals are assumed to anticorrelate with the uncertainty at the stimulus presentation, and to correlate with the reward prediction error term. The SPN-DAN assemblies indeed are anticorrelated with the uncertainty and correlated with the prediction error; thus they convey the prediction signals, crucial to learning. Furthermore we found that this encoding feature is not present in other assembly-types, confirming the hypothesis that different pathways of the VS-VTA circuit specify in different reward-related signals.